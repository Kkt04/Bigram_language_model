# **Bigram Language Model â€” Tiny Shakespeare (PyTorch Implementation)**

This project implements a simple **Bigram Character-Level Language Model** trained on the **Tiny Shakespeare** dataset.  
It follows the approach demonstrated by Andrej Karpathy to show how character-level modeling works at the most basic level.

---

## ðŸ“Œ **Project Overview**

A **Bigram Language Model** predicts the **next character** using **only the current character**.  
There is **no memory**, **no long-term context**, no attention â€” just a lookup table converted into probabilities.

---
