{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm5NqUDnGoj7",
        "outputId": "fdb696e2-57ed-4bc9-e034-7fbd32a31fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-18 10:34:16--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "\rinput.txt.1           0%[                    ]       0  --.-KB/s               \rinput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2025-11-18 10:34:16 (116 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r' , encoding='utf-8') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "U_jcLJyBIoB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzcWnp4jKkVq",
        "outputId": "95bef32f-3911-4e02-9cdb-9a53db03fec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn2GIMN4KtPZ",
        "outputId": "7e49a43d-7a62-4414-af74-9f2737f3b36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1-aI_dQiHtz",
        "outputId": "f0085635-75d7-4220-b473-d451bc834404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '$',\n",
              " '&',\n",
              " \"'\",\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '3',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))"
      ],
      "metadata": {
        "id": "KSBZcntdLFXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L4ZeBi7PiG5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Uva8Ea4iOZ7",
        "outputId": "4f97dbf1-ee49-4512-8ccd-51cba0e4dfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary size = 65\n",
        "# BATCH\n",
        "# Sequence/block_size\n",
        "# P(next_token | current_token)"
      ],
      "metadata": {
        "id": "g4TcdFMMLM5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(''.join(chars))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C62MtPrXMgzK",
        "outputId": "eb90561d-3d33-4bbf-8f0b-e0a81dff7c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch : i for i, ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}"
      ],
      "metadata": {
        "id": "eZ3HXN5EMjd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l : ''.join([itos[i] for i in l])"
      ],
      "metadata": {
        "id": "bHXDw2bCNlrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello\")\n",
        "\n",
        "print(encode(\"abcdefgh\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl8_yWmgNwkU",
        "outputId": "f769b687-8ff3-41fe-b799-219724c04132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "[39, 40, 41, 42, 43, 44, 45, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(encode(\"abcdefgh\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce9HQdvMN03L",
        "outputId": "de07bcd0-48e8-4f6e-9f7b-b5cefaa98b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcdefgh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype= torch.long)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPn-0619N6uw",
        "outputId": "8533b2df-beb7-41d1-8705-1b7bb3368e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Eq7dOuRnClv",
        "outputId": "9933dc17-a42a-4e54-c76e-db2001b0d9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
              "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
              "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
              "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
              "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "8-X7RrW4Od4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary size = 65\n",
        "# BATCH\n",
        "# Sequence/block_size = 8\n",
        "# target_size = 1\n",
        "# P(next_token | current_token)"
      ],
      "metadata": {
        "id": "jTQILvsPOrr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1ohfKEPO98F",
        "outputId": "17a250c2-3f4b-43f4-9c90-6fdaa39c1cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwTHxMtRPCz8",
        "outputId": "db908afe-b085-447f-b8f6-8403912ef0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batches(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y\n"
      ],
      "metadata": {
        "id": "JX2LWywcPPuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batches('train')"
      ],
      "metadata": {
        "id": "7xAaoY02QCVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb.shape, yb.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML9eSc_pQI2M",
        "outputId": "b836cf30-4db2-43e4-e9ca-5d30db80ff36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8]) torch.Size([4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cnvGrlNQMC9",
        "outputId": "db53f000-5e60-4943-a972-0ac3ac089f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[57,  1, 43, 52, 43, 51, 47, 43],\n",
              "        [ 1, 40, 43,  1, 53, 40, 43, 42],\n",
              "        [47, 57, 46,  5, 42,  6,  0, 24],\n",
              "        [47, 52,  1, 39,  1, 51, 47, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixzgidwwQNFX",
        "outputId": "3493ea45-7514-422c-9f26-efc8166740c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1, 43, 52, 43, 51, 47, 43, 57],\n",
              "        [40, 43,  1, 53, 40, 43, 42, 47],\n",
              "        [57, 46,  5, 42,  6,  0, 24, 43],\n",
              "        [52,  1, 39,  1, 51, 47, 50, 43]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n"
      ],
      "metadata": {
        "id": "14rQgtKgQNeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiGramLangauageModel(nn.Module):\n",
        "  # constructor\n",
        "  # forward pass (predict)\n",
        "  # generate (auto-regressive in nature )\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits/probabilities for the next token from a lookup table\n",
        "        # Each character (token) is mapped to a vocab_size-dimensional vector.\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size) # It initializes an embedding layer.\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "        # one char needs 65 probabs.\n",
        "        # B x T chars needs 65 probabs each\n",
        "        # thus total size = B x T x C\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "# auto-regressive in nature\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits, loss = self(idx)\n",
        "\n",
        "      logits = logits[:, -1, :] # becomes (B, C)\n",
        "      # logits have shape B, vocab_size or B x 65\n",
        "      #apply softmax function\n",
        "      probabs = F.softmax(logits, dim=-1)\n",
        "      idx_next = torch.multinomial(probabs, num_samples=1)\n",
        "      idx = torch.cat([idx, idx_next], dim=1)\n",
        "    return idx\n"
      ],
      "metadata": {
        "id": "ELpizk29Qfov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = BiGramLangauageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwpjdOUjUz4A",
        "outputId": "d7b00feb-79ba-4213-be75-07d77ba54cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8649, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "JeeWvpIS,XMEDtHTWseVts!xeDZRjTPChtPt!m!!x;hrcchNZNmW3uOfUUKtHfYE;Wv!xL.:!xF;BRXS$JBbp$ck$NCZwTETgTZD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VoL0WIFU-ci",
        "outputId": "cdc01a24-4101-4988-fce7-1e64feb44654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8649, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(100): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batches('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Uz5u0cVBXu",
        "outputId": "55efaf18-21aa-49c7-e410-4ed8243c305c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.535292148590088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ5vqktaVUKm",
        "outputId": "c0bc3b6d-4daf-4a59-cdcb-0786c0cf0a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "x'sXUtmOUjUkjEG'FQ\n",
            "JCgwQKsHB;HHa!'N?UxXipNRf$aiHc&T3iccfceuuk3ew3j-:DWOWpydcdUFBfuOAevL.z''?fnsHUmkf hwAlpMw'x'A$zr;\n",
            "xuf;vLKfQf!CRR:Q&xQwQAGstSEF;eVApbSTLqgXW3NCemPwprMUpO maj'a'mHZ,cg!jRjYgn\n",
            "f lDAGO-C ;f'tukvqI-bgiJPnkjlWVprNMRTjlOWuboDHMqXUYWKT!VY?kzEvjl\n",
            "umDfwry\n",
            "jlqXZjlaZZzU,pyxeaRS-ag$NClC:hYrtmryhstbp$ XWK;ZsAy3aclWgv$-VA;BdqRiAjltoS$qx'WUtmZ?U?rNhwjhwJnmt;xW;TMw$'z?D.!ymxc,:IRoxn-.\n",
            "!zG&DSpbo bpO3TTe$IwBNC TnkjExzG.IxL$3&ERcfg&ctCTva-S,H-;Rqa-,edvL&zqXOVLVY\n",
            "wBxewyXUhv,&aRzk3zM.3dqM3Rlg&.r!m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros((1, 1), dtype=torch.long)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo-Ks7YVVy6B",
        "outputId": "1ca60261-00e2-47ff-9cf4-2136736921a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ny4OPxzPV4is"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}